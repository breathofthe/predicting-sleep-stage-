{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyPCsDjbm6XVASPZFSrqkLgn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/breathofthe/predicting-sleep-stage-/blob/main/%EB%8B%A4%EC%8B%9C%ED%95%98%EC%9E%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVXEEvgX3BaU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 데이터 로드\n",
        "data = pd.read_csv('/content/train.csv')\n",
        "\n",
        "# IQR 계산\n",
        "Q1 = data['pulse'].quantile(0.25)\n",
        "Q3 = data['pulse'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# 이상치 범위 설정\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# 이상치 제거\n",
        "data_filtered = data[(data['pulse'] >= lower_bound) & (data['pulse'] <= upper_bound)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 sleep_stage의 행 수 계산\n",
        "sleep_stage_counts = data['sleep_stage'].value_counts()\n",
        "\n",
        "# 결과 출력\n",
        "print(sleep_stage_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXZVGXe66wKG",
        "outputId": "9c818b64-7b2a-4ae0-b1db-9beb31dd0fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sleep_stage\n",
            "3.0    6052652\n",
            "0.0    2782033\n",
            "2.0    1880966\n",
            "1.0    1758155\n",
            "4.0     324668\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 로그 변환 적용\n",
        "data_filtered['log_pulse'] = np.log1p(data_filtered['pulse'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmxwrlREuYtJ",
        "outputId": "06a0f77f-25dd-42b5-9ce9-d59b46d1de46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-2b14931f02f5>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_filtered['log_pulse'] = np.log1p(data_filtered['pulse'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# 정규화 적용\n",
        "scaler = MinMaxScaler()\n",
        "data_filtered['normalized_log_pulse'] = scaler.fit_transform(data_filtered[['log_pulse']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiaJt0Wlub4p",
        "outputId": "3a39ce25-21c6-4a67-8109-1e893189c7a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-950a66477b82>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_filtered['normalized_log_pulse'] = scaler.fit_transform(data_filtered[['log_pulse']])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 특성 생성 함수 정의\n",
        "def create_lagged_features(df, lag=29):\n",
        "    lagged_data = pd.DataFrame()\n",
        "    for i in range(1, lag + 1):\n",
        "        lagged_data[f'lag_{i}'] = df['normalized_log_pulse'].shift(i)\n",
        "    lagged_data['sleep_stage'] = df['sleep_stage']\n",
        "    lagged_data = lagged_data.dropna().reset_index(drop=True)\n",
        "    return lagged_data\n",
        "\n",
        "# 특성 생성 적용\n",
        "lagged_data = data_filtered.groupby('subjectID').apply(create_lagged_features).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "fFfpu00fulb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# lagged_data를 활용한 데이터 준비\n",
        "X = lagged_data.drop('sleep_stage', axis=1)\n",
        "y = lagged_data['sleep_stage']\n",
        "\n",
        "# 학습용 데이터와 테스트용 데이터로 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 랜덤 포레스트 모델 초기화 및 학습\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# 예측\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# 성능 평가\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Classification Report:\\n{report}\")"
      ],
      "metadata": {
        "id": "3ZWBOgMsOTHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lightgbm==3.3.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-1DGm-V2o3Q",
        "outputId": "631f5a9d-7bae-4b42-ba21-97d2f71c923b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm==3.3.2 in /usr/local/lib/python3.10/dist-packages (3.3.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm==3.3.2) (0.43.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm==3.3.2) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm==3.3.2) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm==3.3.2) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0->lightgbm==3.3.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0->lightgbm==3.3.2) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 단순 light gbm"
      ],
      "metadata": {
        "id": "lKiCz5NnEQwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 특성과 레이블 분리\n",
        "X = lagged_data.drop('sleep_stage', axis=1)\n",
        "y = lagged_data['sleep_stage']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# LightGBM 데이터셋 준비\n",
        "train_data = lgb.Dataset(X_train, label=y_train)\n",
        "valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
        "\n",
        "# 파라미터 설정\n",
        "params = {\n",
        "    'objective': 'multiclass',\n",
        "    'num_class': len(y.unique()),  # sleep_stage의 클래스 수\n",
        "    'metric': 'multi_logloss',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.9\n",
        "}\n",
        "\n",
        "# 모델 학습\n",
        "gbm = lgb.train(\n",
        "    params,\n",
        "    train_data,\n",
        "    num_boost_round=100,\n",
        "    valid_sets=[train_data, valid_data],\n",
        "    early_stopping_rounds=10\n",
        ")\n",
        "\n",
        "# 예측\n",
        "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
        "y_pred = [list(x).index(max(x)) for x in y_pred]\n",
        "\n",
        "# 성능 평가\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Classification Report:\\n{report}\")"
      ],
      "metadata": {
        "id": "kOFeiFUw2T20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# class 가중치 추가"
      ],
      "metadata": {
        "id": "yW-saluMEUR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight  # 추가된 부분\n",
        "\n",
        "# 클래스 가중치 계산\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
        "\n",
        "# LightGBM 데이터셋 준비\n",
        "train_weights = y_train.map(class_weights_dict).values\n",
        "train_data = lgb.Dataset(X_train, label=y_train, weight=train_weights)\n",
        "valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
        "\n",
        "# 파라미터 설정\n",
        "params = {\n",
        "    'objective': 'multiclass',\n",
        "    'num_class': len(np.unique(y_train)),  # sleep_stage의 클래스 수\n",
        "    'metric': 'multi_logloss',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.8,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'min_data_in_leaf': 20,\n",
        "    'lambda_l1': 0.1,\n",
        "    'lambda_l2': 0.1,\n",
        "    'is_unbalance': False  # 이미 가중치를 직접 설정했으므로 False로 설정\n",
        "}\n",
        "\n",
        "# 모델 학습\n",
        "gbm = lgb.train(\n",
        "    params,\n",
        "    train_data,\n",
        "    num_boost_round=100,\n",
        "    valid_sets=[train_data, valid_data],\n",
        "    early_stopping_rounds=10\n",
        ")\n",
        "\n",
        "# 예측\n",
        "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
        "y_pred = [list(x).index(max(x)) for x in y_pred]\n",
        "\n",
        "# 성능 평가\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Classification Report:\\n{report}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5O3xQDq9ZfW",
        "outputId": "70ab5ace-560d-42b9-e4e0-60170f73a453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.681983 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1508\n",
            "[LightGBM] [Info] Number of data points in the train set: 4397658, number of used features: 29\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[1]\ttraining's multi_logloss: 1.60464\tvalid_1's multi_logloss: 1.60648\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[2]\ttraining's multi_logloss: 1.60032\tvalid_1's multi_logloss: 1.6038\n",
            "[3]\ttraining's multi_logloss: 1.59632\tvalid_1's multi_logloss: 1.60136\n",
            "[4]\ttraining's multi_logloss: 1.59253\tvalid_1's multi_logloss: 1.59907\n",
            "[5]\ttraining's multi_logloss: 1.58898\tvalid_1's multi_logloss: 1.59701\n",
            "[6]\ttraining's multi_logloss: 1.5855\tvalid_1's multi_logloss: 1.59503\n",
            "[7]\ttraining's multi_logloss: 1.58273\tvalid_1's multi_logloss: 1.59326\n",
            "[8]\ttraining's multi_logloss: 1.57968\tvalid_1's multi_logloss: 1.59151\n",
            "[9]\ttraining's multi_logloss: 1.57698\tvalid_1's multi_logloss: 1.58997\n",
            "[10]\ttraining's multi_logloss: 1.57478\tvalid_1's multi_logloss: 1.58862\n",
            "[11]\ttraining's multi_logloss: 1.57223\tvalid_1's multi_logloss: 1.58721\n",
            "[12]\ttraining's multi_logloss: 1.56982\tvalid_1's multi_logloss: 1.58587\n",
            "[13]\ttraining's multi_logloss: 1.56792\tvalid_1's multi_logloss: 1.58471\n",
            "[14]\ttraining's multi_logloss: 1.56601\tvalid_1's multi_logloss: 1.58357\n",
            "[15]\ttraining's multi_logloss: 1.56429\tvalid_1's multi_logloss: 1.58257\n",
            "[16]\ttraining's multi_logloss: 1.56271\tvalid_1's multi_logloss: 1.58162\n",
            "[17]\ttraining's multi_logloss: 1.56089\tvalid_1's multi_logloss: 1.58069\n",
            "[18]\ttraining's multi_logloss: 1.55898\tvalid_1's multi_logloss: 1.57972\n",
            "[19]\ttraining's multi_logloss: 1.55724\tvalid_1's multi_logloss: 1.57885\n",
            "[20]\ttraining's multi_logloss: 1.55553\tvalid_1's multi_logloss: 1.57801\n",
            "[21]\ttraining's multi_logloss: 1.5542\tvalid_1's multi_logloss: 1.57731\n",
            "[22]\ttraining's multi_logloss: 1.55282\tvalid_1's multi_logloss: 1.57663\n",
            "[23]\ttraining's multi_logloss: 1.55138\tvalid_1's multi_logloss: 1.57587\n",
            "[24]\ttraining's multi_logloss: 1.55001\tvalid_1's multi_logloss: 1.57515\n",
            "[25]\ttraining's multi_logloss: 1.54869\tvalid_1's multi_logloss: 1.57452\n",
            "[26]\ttraining's multi_logloss: 1.54762\tvalid_1's multi_logloss: 1.57394\n",
            "[27]\ttraining's multi_logloss: 1.54645\tvalid_1's multi_logloss: 1.57338\n",
            "[28]\ttraining's multi_logloss: 1.54557\tvalid_1's multi_logloss: 1.57289\n",
            "[29]\ttraining's multi_logloss: 1.54437\tvalid_1's multi_logloss: 1.57234\n",
            "[30]\ttraining's multi_logloss: 1.5434\tvalid_1's multi_logloss: 1.57191\n",
            "[31]\ttraining's multi_logloss: 1.54239\tvalid_1's multi_logloss: 1.57139\n",
            "[32]\ttraining's multi_logloss: 1.54145\tvalid_1's multi_logloss: 1.57094\n",
            "[33]\ttraining's multi_logloss: 1.54061\tvalid_1's multi_logloss: 1.57055\n",
            "[34]\ttraining's multi_logloss: 1.53975\tvalid_1's multi_logloss: 1.57009\n",
            "[35]\ttraining's multi_logloss: 1.53883\tvalid_1's multi_logloss: 1.56966\n",
            "[36]\ttraining's multi_logloss: 1.53794\tvalid_1's multi_logloss: 1.56922\n",
            "[37]\ttraining's multi_logloss: 1.53726\tvalid_1's multi_logloss: 1.56882\n",
            "[38]\ttraining's multi_logloss: 1.53653\tvalid_1's multi_logloss: 1.56845\n",
            "[39]\ttraining's multi_logloss: 1.53573\tvalid_1's multi_logloss: 1.56807\n",
            "[40]\ttraining's multi_logloss: 1.53504\tvalid_1's multi_logloss: 1.56765\n",
            "[41]\ttraining's multi_logloss: 1.53434\tvalid_1's multi_logloss: 1.56728\n",
            "[42]\ttraining's multi_logloss: 1.53364\tvalid_1's multi_logloss: 1.56696\n",
            "[43]\ttraining's multi_logloss: 1.53299\tvalid_1's multi_logloss: 1.56657\n",
            "[44]\ttraining's multi_logloss: 1.5324\tvalid_1's multi_logloss: 1.56625\n",
            "[45]\ttraining's multi_logloss: 1.53188\tvalid_1's multi_logloss: 1.56596\n",
            "[46]\ttraining's multi_logloss: 1.53132\tvalid_1's multi_logloss: 1.56565\n",
            "[47]\ttraining's multi_logloss: 1.5307\tvalid_1's multi_logloss: 1.56538\n",
            "[48]\ttraining's multi_logloss: 1.52997\tvalid_1's multi_logloss: 1.56507\n",
            "[49]\ttraining's multi_logloss: 1.52939\tvalid_1's multi_logloss: 1.56482\n",
            "[50]\ttraining's multi_logloss: 1.52887\tvalid_1's multi_logloss: 1.56457\n",
            "[51]\ttraining's multi_logloss: 1.52831\tvalid_1's multi_logloss: 1.56431\n",
            "[52]\ttraining's multi_logloss: 1.52782\tvalid_1's multi_logloss: 1.56406\n",
            "[53]\ttraining's multi_logloss: 1.52732\tvalid_1's multi_logloss: 1.56382\n",
            "[54]\ttraining's multi_logloss: 1.52685\tvalid_1's multi_logloss: 1.56353\n",
            "[55]\ttraining's multi_logloss: 1.52639\tvalid_1's multi_logloss: 1.56333\n",
            "[56]\ttraining's multi_logloss: 1.52587\tvalid_1's multi_logloss: 1.56311\n",
            "[57]\ttraining's multi_logloss: 1.52541\tvalid_1's multi_logloss: 1.56288\n",
            "[58]\ttraining's multi_logloss: 1.52496\tvalid_1's multi_logloss: 1.5627\n",
            "[59]\ttraining's multi_logloss: 1.52452\tvalid_1's multi_logloss: 1.5625\n",
            "[60]\ttraining's multi_logloss: 1.52414\tvalid_1's multi_logloss: 1.56233\n",
            "[61]\ttraining's multi_logloss: 1.52372\tvalid_1's multi_logloss: 1.56207\n",
            "[62]\ttraining's multi_logloss: 1.52327\tvalid_1's multi_logloss: 1.56182\n",
            "[63]\ttraining's multi_logloss: 1.52285\tvalid_1's multi_logloss: 1.56161\n",
            "[64]\ttraining's multi_logloss: 1.52257\tvalid_1's multi_logloss: 1.5614\n",
            "[65]\ttraining's multi_logloss: 1.52208\tvalid_1's multi_logloss: 1.56116\n",
            "[66]\ttraining's multi_logloss: 1.52178\tvalid_1's multi_logloss: 1.56097\n",
            "[67]\ttraining's multi_logloss: 1.52153\tvalid_1's multi_logloss: 1.56081\n",
            "[68]\ttraining's multi_logloss: 1.52119\tvalid_1's multi_logloss: 1.56062\n",
            "[69]\ttraining's multi_logloss: 1.52075\tvalid_1's multi_logloss: 1.56045\n",
            "[70]\ttraining's multi_logloss: 1.52039\tvalid_1's multi_logloss: 1.56026\n",
            "[71]\ttraining's multi_logloss: 1.52002\tvalid_1's multi_logloss: 1.5601\n",
            "[72]\ttraining's multi_logloss: 1.51962\tvalid_1's multi_logloss: 1.5599\n",
            "[73]\ttraining's multi_logloss: 1.51921\tvalid_1's multi_logloss: 1.55973\n",
            "[74]\ttraining's multi_logloss: 1.51889\tvalid_1's multi_logloss: 1.55957\n",
            "[75]\ttraining's multi_logloss: 1.5186\tvalid_1's multi_logloss: 1.55941\n",
            "[76]\ttraining's multi_logloss: 1.5183\tvalid_1's multi_logloss: 1.55923\n",
            "[77]\ttraining's multi_logloss: 1.51805\tvalid_1's multi_logloss: 1.55907\n",
            "[78]\ttraining's multi_logloss: 1.51766\tvalid_1's multi_logloss: 1.5589\n",
            "[79]\ttraining's multi_logloss: 1.51739\tvalid_1's multi_logloss: 1.55874\n",
            "[80]\ttraining's multi_logloss: 1.517\tvalid_1's multi_logloss: 1.55853\n",
            "[81]\ttraining's multi_logloss: 1.51676\tvalid_1's multi_logloss: 1.5584\n",
            "[82]\ttraining's multi_logloss: 1.51651\tvalid_1's multi_logloss: 1.55828\n",
            "[83]\ttraining's multi_logloss: 1.51627\tvalid_1's multi_logloss: 1.55815\n",
            "[84]\ttraining's multi_logloss: 1.51603\tvalid_1's multi_logloss: 1.558\n",
            "[85]\ttraining's multi_logloss: 1.51578\tvalid_1's multi_logloss: 1.55787\n",
            "[86]\ttraining's multi_logloss: 1.51548\tvalid_1's multi_logloss: 1.55766\n",
            "[87]\ttraining's multi_logloss: 1.51526\tvalid_1's multi_logloss: 1.55747\n",
            "[88]\ttraining's multi_logloss: 1.51498\tvalid_1's multi_logloss: 1.55731\n",
            "[89]\ttraining's multi_logloss: 1.51476\tvalid_1's multi_logloss: 1.55713\n",
            "[90]\ttraining's multi_logloss: 1.51449\tvalid_1's multi_logloss: 1.55695\n",
            "[91]\ttraining's multi_logloss: 1.51416\tvalid_1's multi_logloss: 1.55678\n",
            "[92]\ttraining's multi_logloss: 1.51396\tvalid_1's multi_logloss: 1.55664\n",
            "[93]\ttraining's multi_logloss: 1.51376\tvalid_1's multi_logloss: 1.55653\n",
            "[94]\ttraining's multi_logloss: 1.51351\tvalid_1's multi_logloss: 1.55637\n",
            "[95]\ttraining's multi_logloss: 1.51335\tvalid_1's multi_logloss: 1.55625\n",
            "[96]\ttraining's multi_logloss: 1.5131\tvalid_1's multi_logloss: 1.55609\n",
            "[97]\ttraining's multi_logloss: 1.51292\tvalid_1's multi_logloss: 1.55595\n",
            "[98]\ttraining's multi_logloss: 1.51275\tvalid_1's multi_logloss: 1.55581\n",
            "[99]\ttraining's multi_logloss: 1.51254\tvalid_1's multi_logloss: 1.55569\n",
            "[100]\ttraining's multi_logloss: 1.51236\tvalid_1's multi_logloss: 1.55555\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\ttraining's multi_logloss: 1.51236\tvalid_1's multi_logloss: 1.55555\n",
            "Accuracy: 0.25638089347516635\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.34      0.20      0.26    237842\n",
            "         1.0       0.20      0.15      0.18    145329\n",
            "         2.0       0.24      0.34      0.28    161020\n",
            "         3.0       0.57      0.26      0.36    528751\n",
            "         4.0       0.05      0.67      0.09     26473\n",
            "\n",
            "    accuracy                           0.26   1099415\n",
            "   macro avg       0.28      0.33      0.23   1099415\n",
            "weighted avg       0.41      0.26      0.29   1099415\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델의 복잡도를 감소시키면서 class 가중치 추가"
      ],
      "metadata": {
        "id": "iE8Ec2p5EW2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 가중치 계산\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
        "\n",
        "# LightGBM 데이터셋 준비\n",
        "train_weights = y_train.map(class_weights_dict).values\n",
        "train_data = lgb.Dataset(X_train, label=y_train, weight=train_weights)\n",
        "valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
        "\n",
        "# 파라미터 설정\n",
        "params = {\n",
        "    'objective': 'multiclass',\n",
        "    'num_class': len(np.unique(y_train)),\n",
        "    'metric': 'multi_logloss',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 15,  # 모델 복잡도를 낮춤\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.8,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'min_data_in_leaf': 50,  # 리프 노드에 있어야 하는 최소 데이터 수 증가\n",
        "    'lambda_l1': 0.1,\n",
        "    'lambda_l2': 0.1,\n",
        "    'is_unbalance': False  # 클래스 가중치를 직접 설정했으므로 False로 설정\n",
        "}\n",
        "\n",
        "# 모델 학습\n",
        "gbm = lgb.train(\n",
        "    params,\n",
        "    train_data,\n",
        "    num_boost_round=100,\n",
        "    valid_sets=[train_data, valid_data],\n",
        "    early_stopping_rounds=10\n",
        ")\n",
        "\n",
        "# 예측\n",
        "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
        "y_pred = [list(x).index(max(x)) for x in y_pred]\n",
        "\n",
        "# 성능 평가\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Classification Report:\\n{report}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZVmbEZQDp5w",
        "outputId": "2af874f5-1768-44a9-8e5d-d7f3c8542c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.132267 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1508\n",
            "[LightGBM] [Info] Number of data points in the train set: 4397658, number of used features: 29\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[1]\ttraining's multi_logloss: 1.60611\tvalid_1's multi_logloss: 1.60718\n",
            "Training until validation scores don't improve for 10 rounds\n",
            "[2]\ttraining's multi_logloss: 1.60309\tvalid_1's multi_logloss: 1.60517\n",
            "[3]\ttraining's multi_logloss: 1.60036\tvalid_1's multi_logloss: 1.60334\n",
            "[4]\ttraining's multi_logloss: 1.59756\tvalid_1's multi_logloss: 1.60156\n",
            "[5]\ttraining's multi_logloss: 1.59507\tvalid_1's multi_logloss: 1.59995\n",
            "[6]\ttraining's multi_logloss: 1.59291\tvalid_1's multi_logloss: 1.59847\n",
            "[7]\ttraining's multi_logloss: 1.59101\tvalid_1's multi_logloss: 1.5972\n",
            "[8]\ttraining's multi_logloss: 1.58909\tvalid_1's multi_logloss: 1.59581\n",
            "[9]\ttraining's multi_logloss: 1.58744\tvalid_1's multi_logloss: 1.59466\n",
            "[10]\ttraining's multi_logloss: 1.5859\tvalid_1's multi_logloss: 1.59361\n",
            "[11]\ttraining's multi_logloss: 1.58448\tvalid_1's multi_logloss: 1.59262\n",
            "[12]\ttraining's multi_logloss: 1.58294\tvalid_1's multi_logloss: 1.59172\n",
            "[13]\ttraining's multi_logloss: 1.58132\tvalid_1's multi_logloss: 1.59078\n",
            "[14]\ttraining's multi_logloss: 1.57967\tvalid_1's multi_logloss: 1.58992\n",
            "[15]\ttraining's multi_logloss: 1.57844\tvalid_1's multi_logloss: 1.58913\n",
            "[16]\ttraining's multi_logloss: 1.5772\tvalid_1's multi_logloss: 1.58833\n",
            "[17]\ttraining's multi_logloss: 1.57586\tvalid_1's multi_logloss: 1.58763\n",
            "[18]\ttraining's multi_logloss: 1.5748\tvalid_1's multi_logloss: 1.58694\n",
            "[19]\ttraining's multi_logloss: 1.57361\tvalid_1's multi_logloss: 1.58626\n",
            "[20]\ttraining's multi_logloss: 1.57266\tvalid_1's multi_logloss: 1.58567\n",
            "[21]\ttraining's multi_logloss: 1.5714\tvalid_1's multi_logloss: 1.58501\n",
            "[22]\ttraining's multi_logloss: 1.5703\tvalid_1's multi_logloss: 1.58449\n",
            "[23]\ttraining's multi_logloss: 1.56952\tvalid_1's multi_logloss: 1.58398\n",
            "[24]\ttraining's multi_logloss: 1.56825\tvalid_1's multi_logloss: 1.58337\n",
            "[25]\ttraining's multi_logloss: 1.56733\tvalid_1's multi_logloss: 1.58289\n",
            "[26]\ttraining's multi_logloss: 1.56651\tvalid_1's multi_logloss: 1.58243\n",
            "[27]\ttraining's multi_logloss: 1.56581\tvalid_1's multi_logloss: 1.58202\n",
            "[28]\ttraining's multi_logloss: 1.56479\tvalid_1's multi_logloss: 1.5816\n",
            "[29]\ttraining's multi_logloss: 1.56412\tvalid_1's multi_logloss: 1.58123\n",
            "[30]\ttraining's multi_logloss: 1.56334\tvalid_1's multi_logloss: 1.58085\n",
            "[31]\ttraining's multi_logloss: 1.56266\tvalid_1's multi_logloss: 1.5805\n",
            "[32]\ttraining's multi_logloss: 1.56198\tvalid_1's multi_logloss: 1.58016\n",
            "[33]\ttraining's multi_logloss: 1.56132\tvalid_1's multi_logloss: 1.57984\n",
            "[34]\ttraining's multi_logloss: 1.56077\tvalid_1's multi_logloss: 1.57952\n",
            "[35]\ttraining's multi_logloss: 1.56009\tvalid_1's multi_logloss: 1.57923\n",
            "[36]\ttraining's multi_logloss: 1.55949\tvalid_1's multi_logloss: 1.57889\n",
            "[37]\ttraining's multi_logloss: 1.55863\tvalid_1's multi_logloss: 1.57839\n",
            "[38]\ttraining's multi_logloss: 1.55774\tvalid_1's multi_logloss: 1.5779\n",
            "[39]\ttraining's multi_logloss: 1.55723\tvalid_1's multi_logloss: 1.57759\n",
            "[40]\ttraining's multi_logloss: 1.5567\tvalid_1's multi_logloss: 1.57731\n",
            "[41]\ttraining's multi_logloss: 1.55592\tvalid_1's multi_logloss: 1.57685\n",
            "[42]\ttraining's multi_logloss: 1.55543\tvalid_1's multi_logloss: 1.57651\n",
            "[43]\ttraining's multi_logloss: 1.5548\tvalid_1's multi_logloss: 1.57614\n",
            "[44]\ttraining's multi_logloss: 1.55426\tvalid_1's multi_logloss: 1.57587\n",
            "[45]\ttraining's multi_logloss: 1.55358\tvalid_1's multi_logloss: 1.57544\n",
            "[46]\ttraining's multi_logloss: 1.55288\tvalid_1's multi_logloss: 1.57517\n",
            "[47]\ttraining's multi_logloss: 1.55223\tvalid_1's multi_logloss: 1.57487\n",
            "[48]\ttraining's multi_logloss: 1.55175\tvalid_1's multi_logloss: 1.57464\n",
            "[49]\ttraining's multi_logloss: 1.55118\tvalid_1's multi_logloss: 1.57433\n",
            "[50]\ttraining's multi_logloss: 1.55078\tvalid_1's multi_logloss: 1.57416\n",
            "[51]\ttraining's multi_logloss: 1.55038\tvalid_1's multi_logloss: 1.57395\n",
            "[52]\ttraining's multi_logloss: 1.54989\tvalid_1's multi_logloss: 1.57375\n",
            "[53]\ttraining's multi_logloss: 1.5494\tvalid_1's multi_logloss: 1.57348\n",
            "[54]\ttraining's multi_logloss: 1.54905\tvalid_1's multi_logloss: 1.57332\n",
            "[55]\ttraining's multi_logloss: 1.54862\tvalid_1's multi_logloss: 1.57313\n",
            "[56]\ttraining's multi_logloss: 1.54817\tvalid_1's multi_logloss: 1.57292\n",
            "[57]\ttraining's multi_logloss: 1.54782\tvalid_1's multi_logloss: 1.57279\n",
            "[58]\ttraining's multi_logloss: 1.54743\tvalid_1's multi_logloss: 1.57267\n",
            "[59]\ttraining's multi_logloss: 1.54695\tvalid_1's multi_logloss: 1.57241\n",
            "[60]\ttraining's multi_logloss: 1.54666\tvalid_1's multi_logloss: 1.57228\n",
            "[61]\ttraining's multi_logloss: 1.5463\tvalid_1's multi_logloss: 1.57201\n",
            "[62]\ttraining's multi_logloss: 1.54583\tvalid_1's multi_logloss: 1.5718\n",
            "[63]\ttraining's multi_logloss: 1.54538\tvalid_1's multi_logloss: 1.57155\n",
            "[64]\ttraining's multi_logloss: 1.54501\tvalid_1's multi_logloss: 1.5714\n",
            "[65]\ttraining's multi_logloss: 1.54474\tvalid_1's multi_logloss: 1.57123\n",
            "[66]\ttraining's multi_logloss: 1.5445\tvalid_1's multi_logloss: 1.57111\n",
            "[67]\ttraining's multi_logloss: 1.54404\tvalid_1's multi_logloss: 1.57094\n",
            "[68]\ttraining's multi_logloss: 1.54369\tvalid_1's multi_logloss: 1.57072\n",
            "[69]\ttraining's multi_logloss: 1.54317\tvalid_1's multi_logloss: 1.57048\n",
            "[70]\ttraining's multi_logloss: 1.5429\tvalid_1's multi_logloss: 1.57034\n",
            "[71]\ttraining's multi_logloss: 1.54263\tvalid_1's multi_logloss: 1.57022\n",
            "[72]\ttraining's multi_logloss: 1.54225\tvalid_1's multi_logloss: 1.57008\n",
            "[73]\ttraining's multi_logloss: 1.54196\tvalid_1's multi_logloss: 1.56993\n",
            "[74]\ttraining's multi_logloss: 1.54166\tvalid_1's multi_logloss: 1.56977\n",
            "[75]\ttraining's multi_logloss: 1.54137\tvalid_1's multi_logloss: 1.56964\n",
            "[76]\ttraining's multi_logloss: 1.54094\tvalid_1's multi_logloss: 1.56946\n",
            "[77]\ttraining's multi_logloss: 1.54047\tvalid_1's multi_logloss: 1.56923\n",
            "[78]\ttraining's multi_logloss: 1.54011\tvalid_1's multi_logloss: 1.56901\n",
            "[79]\ttraining's multi_logloss: 1.53974\tvalid_1's multi_logloss: 1.56887\n",
            "[80]\ttraining's multi_logloss: 1.53924\tvalid_1's multi_logloss: 1.56867\n",
            "[81]\ttraining's multi_logloss: 1.53882\tvalid_1's multi_logloss: 1.5685\n",
            "[82]\ttraining's multi_logloss: 1.5385\tvalid_1's multi_logloss: 1.56837\n",
            "[83]\ttraining's multi_logloss: 1.53823\tvalid_1's multi_logloss: 1.56824\n",
            "[84]\ttraining's multi_logloss: 1.53789\tvalid_1's multi_logloss: 1.56804\n",
            "[85]\ttraining's multi_logloss: 1.53761\tvalid_1's multi_logloss: 1.56788\n",
            "[86]\ttraining's multi_logloss: 1.53723\tvalid_1's multi_logloss: 1.56775\n",
            "[87]\ttraining's multi_logloss: 1.53692\tvalid_1's multi_logloss: 1.56761\n",
            "[88]\ttraining's multi_logloss: 1.53659\tvalid_1's multi_logloss: 1.56743\n",
            "[89]\ttraining's multi_logloss: 1.53628\tvalid_1's multi_logloss: 1.56725\n",
            "[90]\ttraining's multi_logloss: 1.53598\tvalid_1's multi_logloss: 1.5671\n",
            "[91]\ttraining's multi_logloss: 1.53575\tvalid_1's multi_logloss: 1.56697\n",
            "[92]\ttraining's multi_logloss: 1.53557\tvalid_1's multi_logloss: 1.56687\n",
            "[93]\ttraining's multi_logloss: 1.53535\tvalid_1's multi_logloss: 1.56674\n",
            "[94]\ttraining's multi_logloss: 1.53518\tvalid_1's multi_logloss: 1.56664\n",
            "[95]\ttraining's multi_logloss: 1.53499\tvalid_1's multi_logloss: 1.56652\n",
            "[96]\ttraining's multi_logloss: 1.53481\tvalid_1's multi_logloss: 1.5664\n",
            "[97]\ttraining's multi_logloss: 1.53465\tvalid_1's multi_logloss: 1.56629\n",
            "[98]\ttraining's multi_logloss: 1.53436\tvalid_1's multi_logloss: 1.56609\n",
            "[99]\ttraining's multi_logloss: 1.53403\tvalid_1's multi_logloss: 1.56588\n",
            "[100]\ttraining's multi_logloss: 1.53387\tvalid_1's multi_logloss: 1.56578\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\ttraining's multi_logloss: 1.53387\tvalid_1's multi_logloss: 1.56578\n",
            "Accuracy: 0.2513409404092176\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.22      0.27    237842\n",
            "         1.0       0.20      0.11      0.15    145329\n",
            "         2.0       0.24      0.31      0.27    161020\n",
            "         3.0       0.57      0.26      0.36    528751\n",
            "         4.0       0.04      0.67      0.08     26473\n",
            "\n",
            "    accuracy                           0.25   1099415\n",
            "   macro avg       0.28      0.32      0.23   1099415\n",
            "weighted avg       0.41      0.25      0.29   1099415\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 언더샘플링과 오버샘플링을 합친 기법"
      ],
      "metadata": {
        "id": "p2lmuFZmItqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.loc[:, 'log_pulse'] = np.log1p(test_data['pulse'])\n",
        "test_data.loc[:, 'normalized_log_pulse'] = scaler.transform(test_data[['log_pulse']])\n",
        "test_lagged_data = test_data.groupby('subjectID').apply(create_lagged_features).reset_index(drop=True)\n",
        "X_test_final = test_lagged_data.drop('sleep_stage', axis=1)\n",
        "test_pred = gbm.predict(X_test_final, num_iteration=gbm.best_iteration)\n",
        "test_pred_classes = [list(x).index(max(x)) for x in test_pred]\n"
      ],
      "metadata": {
        "id": "Rb7ltBSJ30iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solution_sample['sleep_stage'] = test_pred_classes\n"
      ],
      "metadata": {
        "id": "_sIRd0is32_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_file_path = '/mnt/data/solution.csv'\n",
        "solution_sample.to_csv(output_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "mvZkNNV23466"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}